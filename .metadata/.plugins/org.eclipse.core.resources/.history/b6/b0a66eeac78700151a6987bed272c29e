package io.github.cr3ahal0.swc;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;

public class Crawler {

	private final static int MAX_DEPTH = 20;
	
	private Map<String, Set<String>> results;
	
	class Job implements Runnable
	{

		public Job(String url) {
			
		}
		
		public void run() {
			
		}
		
	}
	
	public static void main(String[] args) {
		String url = "http://google.com";
		
		Crawler c = new Crawler();
		c.crawl(url, 1);
	}
	
	public Crawler() {
		results = new HashMap<String, Set<String>>();
	}
	
	public void crawl(String url, int depth) {
		if (depth > MAX_DEPTH) {
			return;
		}
		
		List<String> found = new ArrayList<String>();
		
		Pattern p = Pattern.compile("href=\"(.*?)\"");
		Matcher m = p.matcher(html);
		String url = null;
		if (m.find()) {
		    url = m.group(1); // this variable should contain the link URL
		}
		
		for (String aUri : found) {
			crawl(aUri, depth+1);
		}
		
	}
	
}
